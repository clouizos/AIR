
\documentclass[12pt]{amsart}
\usepackage{geometry} % see geometry.pdf on how to lay out the page. There's lots.
\geometry{a4paper} % or letter or a5paper or ... etc
% \geometry{landscape} % rotated page geometry

% See the ``Article customise'' template for come common customisations


%%% BEGIN DOCUMENT
\begin{document}

\section{Description of the data}
For our research we used document contents and search engine logs that were generously made available to us by the dutch institute for video and sound [1]. The institute maintains a large database with video fragments with textual description. These video fragments are searched by expert users of the search engine and used in television broadcastings. Users of this service are typically journalists and they pay for this service.

The textual description of the video fragments are the documents that are being searched to retrieve video fragments. They are on average $130$ words long, written in Dutch. The documents have three fields, Title, Description and Summary, which are all optional. Documents also have a genre, which can be one of twelve. The query log contains raw query text and click-through as well as purchase information.  There are about $400.000$ in the collection that were returned after a query was deployed. There are $918$ distinct users, but not all of them have queries with click-through data. $166$ users do have $50$ or more queries that have at least one clicked and one un-clicked returned document for that query. In our experiments we only used the the latter group of 166 users to assure both positive and negative examples and sufficient query text for user specific query language modelling. On average, these users produced $160$ queries. The largest number of queries for a given user is 1600 queries. The average query length is $2.18$ words.

\section{Collaborative Document Re-Ranking}
\subsection{Approach}
%What is document re-ranking? (re-ranking formula)
When we use collaborative document re-ranking, we will re-rank the documents returned by a search engine based on comparing the user to a number of most similar users and upgrade the ranking score of a document proportional to the user similarity with other users that clicked the documents. As the search engine we are using does not provide any ranking whatsoever, we will assign a ranking sore based on user similarity only. The ranking score for a document $d$ for a given user $u_a$ is defined as: 
$$r(d, u_a) = \sum\limits_{u_b \in U}\textit{sim}(u_a, u_b)\delta(u_b, d)$$
where $U$ denotes the set of $k$ most similar users, $\textit{sim}(u_a, u_b)$ is the function that computes the user similarity and $\delta(u_b, d) = 1$ if user $u_b$ clicked document $d$ and zero otherwise. A lot of different methods can be used to compute $\textit{sim}(u_a, u_b)$, we have chosen a language modeling approach in which we define $\textit{sim}(u_a, u_b)$ as:
$$ \textit{sim}(u_a, u_b) = \frac{1}{|Q_{u_a}|}\sum\limits_{q \in Q_{u_a}} p(q|u_b)$$
where $Q_{u_a}$ is the set of queries from user $u_a$ and $p(q|u)$ can be computed as:
$$p(q|u) = \prod\limits_{q_i \in q} \frac{\textit{tf}_{q_i, u}+1}{\sum\limits_{x \in V_u} \textit{tf}_{x, u}}$$
where $V_u$ denotes the vocabulary of user $u$. We can define the vocabulary in different ways. We have evaluated two methods of collaborative document re-ranking, the first one uses the Simple User Language Model (SULM) where the user's vocabulary consists only of its queries. In addition to this, we have also defined the vocabulary as the users's queries complemented by all words from the documents the user has clicked. We call this the Extended User Language Model (EULM).
%So, how to get the set of most similar users? 
%Language model, user sim measure 
%Notice log space
\subsection{Results}
We compare our approach against a random ranking (RANDOM) and greatest hits ranking where documents are ranked according to the number of clicks they got (POP).
%Report MAP, P@1, P@3 and MRR
\subsection{Discussion}
%Query also plays a role. 

\subsection{References}
[1] http://www.beeldengeluid.nl/over-beeld-en-geluid

\end{document}